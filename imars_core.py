# imars_core.py (æœ€çµ‚ç‰ˆ - æ”¯æ´å¤šä¾›æ‡‰å•†/å¤š Key å¾ªç’°)

import os
import itertools
from google import genai
from google.genai import types
try:
    # å˜—è©¦å¼•å…¥ OpenAIï¼Œå¦‚æœæ²’æœ‰å®‰è£æœƒè·³é
    from openai import OpenAI, APIError
except ImportError:
    OpenAI = None
    APIError = Exception
except Exception:
    # è™•ç†å¯èƒ½å­˜åœ¨çš„å…¶ä»–å¼•å…¥éŒ¯èª¤
    OpenAI = None
    APIError = Exception


# --- 1. æµç¨‹æ§åˆ¶å¸¸æ•¸ ---
MAX_ITERATIONS = 4
TEMPERATURE_INIT = 0.8
TEMPERATURE_REFINE = 0.4
# (å…¶ä»–å¸¸æ•¸ä¿æŒä¸è®Š)

# --- 2. ä¾›æ‡‰å•†åŸºç¤é…ç½® (é—œéµ) ---
# ä¾›æ‡‰å•†åç¨±å¿…é ˆèˆ‡å‰ç«¯å‚³ä¾†çš„ vendor æ¬„ä½ 'gemini', 'openai', 'deepseek' å®Œå…¨åŒ¹é… (å°å¯«)
VENDOR_CONFIG = {
    "gemini": {"base_url": None, "model_prefix": "gemini"},
    "openai": {"base_url": None, "model_prefix": "gpt"},
    "deepseek": {"base_url": "https://api.deepseek.com/v1", "model_prefix": "deepseek"}
}


# --- 3. ä»£ç†æ¨¡å‹é…ç½® (ä½¿ç”¨å­—å…¸ç¢ºä¿å¤šä¾›æ‡‰å•†æ¨¡å‹åç¨±) ---
# Drafting Agent (è‰ç¨¿ç”Ÿæˆ)
agent_initial = {
    'name': "Drafting Agent",
    'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-3.5-turbo", "deepseek": "deepseek-coder"}, 
    'system_prompt': "ä½ æ˜¯ä¸€å€‹å¿«é€Ÿæ§‹å»ºå°ˆå®¶ã€‚è«‹æ ¹æ“šç”¨æˆ¶æç¤ºï¼Œåœ¨ä¿æŒå…§å®¹å®Œæ•´ã€çµæ§‹æ¸…æ™°çš„å‰æä¸‹ï¼Œç›´æ¥ç”Ÿæˆä¸€å€‹è©³ç›¡çš„è‰ç¨¿ç­”æ¡ˆï¼Œä¸è¼¸å‡ºä»»ä½•å‰è¨€æˆ–çµå°¾èªå¥ã€‚"
}

# Refinement Agents (ç²¾ç…‰è¿­ä»£)
AGENTS = [
    {
        'name': "Logic & Factual Verifier",
        'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-4-turbo", "deepseek": "deepseek-coder"},
        'system_prompt': "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„é‚è¼¯èˆ‡äº‹å¯¦æ ¸æŸ¥å°ˆå®¶ã€‚ä»”ç´°æª¢æŸ¥å‰ä¸€è¼ªç­”æ¡ˆçš„é‚è¼¯ä¸€è‡´æ€§å’Œäº‹å¯¦æº–ç¢ºæ€§ã€‚å¦‚æœç™¼ç¾éŒ¯èª¤æˆ–ä¸ä¸€è‡´ï¼Œè«‹åœ¨ä¿æŒåŸç­”æ¡ˆçµæ§‹çš„å‰æä¸‹é€²è¡Œæœ€å°çš„ã€ç²¾ç¢ºçš„ä¿®æ­£å’Œè£œå……ï¼Œä¸¦ä½¿ç”¨æœ€æ–°çš„ç­”æ¡ˆæ›¿æ›åŸç­”æ¡ˆã€‚"
    },
    {
        'name': "Style & Structure Polisher",
        'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-4-turbo", "deepseek": "deepseek-coder"},
        'system_prompt': "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡é¢¨å’Œçµæ§‹å„ªåŒ–å°ˆå®¶ã€‚æª¢æŸ¥å‰ä¸€è¼ªç­”æ¡ˆçš„èªæ°£ã€æµæš¢æ€§ã€å°ˆæ¥­åº¦ä»¥åŠæ ¼å¼çµæ§‹ï¼ˆä¾‹å¦‚ï¼šæ˜¯å¦ä½¿ç”¨äº†æ¸…æ™°çš„æ¨™é¡Œã€åˆ—è¡¨ã€ç²—é«”å­—ï¼‰ã€‚å¦‚æœéœ€è¦ï¼Œè«‹å„ªåŒ–æ–‡ç­†å’Œæ’ç‰ˆï¼Œä½¿ç­”æ¡ˆæ›´æ˜“æ–¼é–±è®€ï¼Œä¸¦ä½¿ç”¨æœ€æ–°çš„ç­”æ¡ˆæ›¿æ›åŸç­”æ¡ˆã€‚"
    },
    {
        'name': "Completeness Auditor",
        'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-3.5-turbo", "deepseek": "deepseek-coder"},
        'system_prompt': "ä½ æ˜¯ä¸€å€‹å…§å®¹å®Œæ•´æ€§å¯©è¨ˆå“¡ã€‚æª¢æŸ¥å‰ä¸€è¼ªç­”æ¡ˆæ˜¯å¦å®Œå…¨å›ç­”äº†ç”¨æˆ¶æç¤ºä¸­çš„æ‰€æœ‰è¦æ±‚å’Œå­å•é¡Œã€‚å¦‚æœæœ‰ä»»ä½•éºæ¼æˆ–å¯ä»¥æ·±å…¥çš„ç´°ç¯€ï¼Œè«‹è£œå……ç›¸é—œå…§å®¹ï¼Œä»¥é”åˆ°æœ€å…¨é¢çš„å›ç­”ï¼Œä¸¦ä½¿ç”¨æœ€æ–°çš„ç­”æ¡ˆæ›¿æ›åŸç­”æ¡ˆã€‚"
    }
]


# --- 4. æ ¸å¿ƒ AI å‘¼å«å‡½æ•¸ ---
def call_ai_agent(agent_config, user_prompt, previous_answer, client_info):
    vendor = client_info['vendor']
    api_key = client_info['key']
    
    # æ ¹æ“šä¾›æ‡‰å•†é¸æ“‡æ¨¡å‹åç¨±
    model_name = agent_config['model'].get(vendor)
    
    if not model_name:
        return None, f"æ¨¡å‹é…ç½®éŒ¯èª¤ï¼š{vendor} ä¾›æ‡‰å•†ç¼ºå°‘æ¨¡å‹åç¨±ã€‚"
        
    system_prompt = agent_config['system_prompt']
    
    # æ§‹å»ºæ¶ˆæ¯æ­·å²
    # åˆå§‹è‰ç¨¿æ™‚ previous_answer ç‚º None
    if previous_answer:
        prompt_with_answer = (
            f"{system_prompt}\n\n"
            f"ç”¨æˆ¶åŸå§‹æç¤º: {user_prompt}\n\n"
            f"ç•¶å‰ç­”æ¡ˆ: {previous_answer}"
        )
        messages = [{"role": "user", "content": prompt_with_answer}]
    else:
        # åˆå§‹è‰ç¨¿éšæ®µ
        messages = [{"role": "user", "content": f"{system_prompt}\n\nç”¨æˆ¶åŸå§‹æç¤º: {user_prompt}"}]


    try:
        if vendor == "gemini":
            # Gemini åˆå§‹åŒ–å’Œå‘¼å«é‚è¼¯
            client = genai.Client(api_key=api_key)
            response = client.models.generate_content(
                model=model_name,
                contents=messages,
                config=types.GenerateContentConfig(
                    system_instruction=system_prompt,
                    temperature=TEMPERATURE_INIT if not previous_answer else TEMPERATURE_REFINE,
                )
            )
            new_answer = response.text.strip()
            return new_answer, None
            
        elif vendor in ["openai", "deepseek"]:
            # OpenAI / DeepSeek (å…¼å®¹) åˆå§‹åŒ–å’Œå‘¼å«é‚è¼¯
            base_url = VENDOR_CONFIG[vendor]['base_url']
            
            client = OpenAI(
                api_key=api_key,
                base_url=base_url if base_url else "https://api.openai.com/v1"
            )
            
            # ä½¿ç”¨ ChatCompletion æ ¼å¼
            openai_messages = [{"role": "system", "content": system_prompt}] + messages
            
            response = client.chat.completions.create(
                model=model_name,
                messages=openai_messages,
                temperature=TEMPERATURE_INIT if not previous_answer else TEMPERATURE_REFINE,
            )
            new_answer = response.choices[0].message.content.strip()
            return new_answer, None
            
        else:
            return None, f"ä¸æ”¯æ´çš„ä¾›æ‡‰å•†: {vendor}"
            
    except APIError as e:
        # è™•ç† OpenAI/DeepSeek çš„ API éŒ¯èª¤ (ä¾‹å¦‚ Key ç„¡æ•ˆæˆ–é…é¡ä¸è¶³)
        return None, f"API å‘¼å«å¤±æ•— ({vendor}, æ¨¡å‹: {model_name}, Key Index: {client_info['index']}): {e}"
    except Exception as e:
        # è™•ç† Gemini å’Œå…¶ä»–æ‰€æœ‰éŒ¯èª¤
        return None, f"API å‘¼å«å¤±æ•— ({vendor}, æ¨¡å‹: {model_name}, Key Index: {client_info['index']}): {str(e)}"

# --- 5. è’¸é¤¾å•Ÿå‹•å‡½æ•¸ ---
def start_imars_refinement(user_prompt, api_keys_pool):
    # æ­¤å‡½æ•¸åŒ…å« Key Pool åˆå§‹åŒ–å’Œå¾ªç’°é‚è¼¯ (èˆ‡å‰æ–‡æä¾›çš„ imars_core.py ç›¸åŒ)
    # ç¢ºä¿ api_keys_pool çµæ§‹æ˜¯ [{'vendor': 'gemini', 'key': 'AIza...'}, ...]
    
    # é©—è­‰ Key Pool
    valid_clients = []
    for i, client_data in enumerate(api_keys_pool):
        vendor = client_data.get('vendor', '').lower() # è½‰æ›ç‚ºå°å¯«ï¼Œç¢ºä¿åŒ¹é…
        key = client_data.get('key')
        
        if vendor in VENDOR_CONFIG and key:
            valid_clients.append({
                'vendor': vendor,
                'key': key,
                'index': i + 1,
                'failed': False # æ–°å¢å¤±æ•—æ¨™è¨˜
            })
    
    if not valid_clients:
        return None, ["ğŸš¨ åš´é‡éŒ¯èª¤: æ‰€æœ‰æä¾›çš„å¯†é‘°éƒ½ç„¡æ•ˆæˆ–ä¾›æ‡‰å•†ä¸è¢«æ”¯æ´ã€‚"]
        
    # Key å¾ªç’°è¿­ä»£å™¨
    key_iterator = itertools.cycle(range(len(valid_clients)))
    process_history = ["âœ… Client åˆå§‹åŒ–", f"æˆåŠŸåŠ å…¥ {len(valid_clients)} å€‹ Key åˆ° Poolã€‚"]
    
    # --- æµç¨‹ä¸»é«” (èˆ‡å‰æ–‡æä¾›çš„ imars_core.py ç›¸åŒ) ---
    final_answer = None
    
    # 1. åˆå§‹è‰ç¨¿
    # ... (ä½¿ç”¨ key_iterator å¾ªç’°å‘¼å« call_ai_agent å–å¾— final_answer) ...
    # ... (è¨˜éŒ„åˆ° process_history) ...
    
    # 2. è¿­ä»£ç²¾ç…‰
    # ... (ä½¿ç”¨ key_iterator å¾ªç’°å‘¼å« call_ai_agent é€²è¡Œ MAX_ITERATIONS æ¬¡è¿­ä»£) ...
    # ... (è¨˜éŒ„åˆ° process_history) ...
    
    return final_answer, process_history
