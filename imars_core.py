# imars_core.py (æœ€çµ‚ç™¼å¸ƒç‰ˆæœ¬ - æ”¯æ´å¤š AI ä¾›æ‡‰å•†æ¦‚å¿µ)

import os
from google import genai 
from google.genai import types 
# TODO: æœªä¾†åœ¨æ­¤è™•å¼•å…¥å…¶ä»–ä¾›æ‡‰å•†çš„ SDKï¼Œå¦‚: from openai import OpenAI

# --- 1. æµç¨‹æ§åˆ¶å¸¸æ•¸ ---
MAX_ITERATIONS = 4 
TEMPERATURE_INIT = 0.8 
TEMPERATURE_REFINE = 0.4 

# --- 2. ä»£ç†æ¨¡å‹é…ç½® (Agent Pool) ---

# åˆå§‹è‰ç¨¿ä»£ç† (Agent 0)
agent_initial = {
    'name': "Drafting Agent",
    'model': "gemini-2.5-flash", 
    'system_prompt': (
        "ä½ æ˜¯ä¸€å€‹å¿«é€Ÿæ§‹å»ºå°ˆå®¶ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šç”¨æˆ¶çš„æç¤ºï¼Œç”Ÿæˆä¸€å€‹çµæ§‹æ¸…æ™°ã€å…§å®¹å®Œæ•´çš„åˆå§‹è‰ç¨¿ã€‚ "
        "é‡é»åœ¨æ–¼è¦†è“‹æ‰€æœ‰é—œéµé»ï¼Œè€Œéç´°ç¯€çš„çµ•å°æº–ç¢ºæ€§ã€‚ä½¿ç”¨ Markdown æ ¼å¼ã€‚"
    )
}

# ç²¾ç…‰ä»£ç†æ±  (å¾ªç’°ä½¿ç”¨)
AGENTS = [
    {
        'name': "Logic & Factual Verifier",
        'model': "gemini-2.5-flash",
        'system_prompt': (
            "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„é‚è¼¯èˆ‡äº‹å¯¦æ ¸æŸ¥å°ˆå®¶ã€‚ä»”ç´°å¯©æŸ¥æä¾›çš„ç•¶å‰ç­”æ¡ˆï¼Œé‡é»æ‰¾å‡ºé‚è¼¯éŒ¯èª¤ã€çŸ›ç›¾æˆ–éæ™‚çš„äº‹å¯¦ã€‚ "
            "åªå°éŒ¯èª¤å’Œä¸æº–ç¢ºä¹‹è™•é€²è¡Œä¿®æ”¹å’Œä¿®æ­£ï¼Œä¸¦ä¿æŒç­”æ¡ˆåŸæœ‰çš„çµæ§‹ã€‚"
        )
    },
    {
        'name': "Style & Structure Polisher",
        'model': "gemini-2.5-flash",
        'system_prompt': (
            "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡é¢¨å’Œçµæ§‹å„ªåŒ–å¸«ã€‚ä½ çš„ä»»å‹™æ˜¯æå‡ç•¶å‰ç­”æ¡ˆçš„é–±è®€æµæš¢æ€§ã€å°ˆæ¥­åº¦ä»¥åŠæ ¼å¼ç¾è§€åº¦ã€‚ "
            "ç¢ºä¿ä½¿ç”¨æ¸…æ™°çš„æ¨™é¡Œã€åˆ—è¡¨å’Œç²—é«”å­—ï¼Œä½¿å…¶æ˜“æ–¼æƒæå’Œé–±è®€ã€‚ä¸è¦æ”¹è®Šæ ¸å¿ƒå…§å®¹ã€‚"
        )
    },
    {
        'name': "Completeness Auditor",
        'model': "gemini-2.5-flash",
        'system_prompt': (
            "ä½ æ˜¯ä¸€å€‹çŸ¥è­˜å®Œæ•´æ€§å¯©è¨ˆå¸«ã€‚å°æ¯”åŸå§‹å•é¡Œèˆ‡ç•¶å‰ç­”æ¡ˆï¼Œè©•ä¼°æ˜¯å¦éºæ¼äº†ä»»ä½•ç”¨æˆ¶æç¤ºä¸­è¦æ±‚çš„é—œéµè³‡è¨Šæˆ–å­è©±é¡Œã€‚ "
            "å¦‚æœç™¼ç¾éºæ¼ï¼Œè«‹è£œå……å¿…è¦çš„å…§å®¹ä»¥è®“ç­”æ¡ˆæ›´å…¨é¢ï¼Œä¸¦å°‡æ–°å…§å®¹ç„¡ç¸«æ•´åˆåˆ°ç¾æœ‰çµæ§‹ä¸­ã€‚"
        )
    }
]


def call_ai_agent(agent_config, user_prompt, previous_answer, client_instance, vendor):
    """
    å¯¦éš›å‘¼å« AI API é€²è¡Œè’¸é¤¾èˆ‡ç²¾ç…‰ã€‚æ ¹æ“šå‚³å…¥çš„ vendor åŸ·è¡Œå°æ‡‰çš„ API å‘¼å«ã€‚
    """
    if not client_instance:
        raise ConnectionError("AI Client å°šæœªåˆå§‹åŒ–ã€‚è«‹æª¢æŸ¥ API Keyã€‚")
    
    # 1. æç¤ºæ§‹å»º
    if agent_config['name'] == "Drafting Agent":
        full_prompt = (
            f"ç”¨æˆ¶åŸå§‹å•é¡Œï¼š\n{user_prompt}\n\n"
            f"{previous_answer}" 
        )
        temperature = TEMPERATURE_INIT
    else:
        full_prompt = (
            f"ç”¨æˆ¶åŸå§‹å•é¡Œï¼š\n{user_prompt}\n\n"
            f"--- å¾…ç²¾ç…‰çš„ç•¶å‰ç­”æ¡ˆ ---\n{previous_answer}\n\n"
            f"è«‹æ ¹æ“šæ‚¨çš„å°ˆæ¥­è·è²¬ï¼Œç›´æ¥è¼¸å‡ºç²¾ç…‰å¾Œçš„å®Œæ•´ç­”æ¡ˆã€‚"
        )
        temperature = TEMPERATURE_REFINE

    # 2. åŸ·è¡Œ API å‘¼å« (ä¾›æ‡‰å•†åˆ¤æ–·)
    model = agent_config['model']

    if vendor == 'gemini':
        # è¨­ç½® Gemini API è«‹æ±‚é…ç½®
        config = types.GenerateContentConfig(
            system_instruction=agent_config['system_prompt'],
            temperature=temperature
        )
        
        try:
            # å‘¼å« Gemini
            response = client_instance.models.generate_content(
                model=model,
                contents=full_prompt,
                config=config,
            )
            return response.text
        except Exception as e:
            raise RuntimeError(f"Gemini API å‘¼å«å¤±æ•— ({agent_config['name']}, æ¨¡å‹: {model}): {str(e)}")
    
    # elif vendor == 'openai':
    #     raise NotImplementedError("OpenAI ä¾›æ‡‰å•†å°šæœªå¯¦ä½œã€‚")
        
    else:
        # å¦‚æœä¾›æ‡‰å•†é¡å‹ç„¡æ³•è­˜åˆ¥ï¼Œå‰‡å ±éŒ¯
        raise TypeError(f"ä¸æ”¯æ´æˆ–ç„¡æ³•è­˜åˆ¥çš„ AI ä¾›æ‡‰å•†: {vendor}")


def start_imars_refinement(user_prompt, api_config={}): 
    """
    ä¸»æ§å‡½æ•¸ï¼šåŸ·è¡Œå¤š Agent è¿­ä»£è’¸é¤¾æµç¨‹ã€‚
    api_config = {'vendor': 'gemini'|'openai'|..., 'key': 'YOUR_API_KEY', 'model_override': 'model_name'}
    """
    # éŒ¯èª¤æª¢æŸ¥ï¼šç¢ºä¿é…ç½®å’Œå¯†é‘°å­˜åœ¨
    if not api_config or not api_config.get('key') or not api_config.get('vendor'):
        error_log = [{'type': 'System', 'title': 'ğŸš¨ åš´é‡éŒ¯èª¤', 'content': 'è«‹æä¾›åŒ…å«ä¾›æ‡‰å•†(vendor)å’Œå¯†é‘°(key)çš„ API é…ç½®ã€‚'}]
        return None, error_log

    process_history = []
    vendor = api_config['vendor'].lower()
    api_key = api_config['key']
    client = None
    
    # 1. åˆå§‹åŒ– Client (æ ¹æ“šä¾›æ‡‰å•†é¡å‹)
    try:
        if vendor == 'gemini':
            client = genai.Client(api_key=api_key)
        # elif vendor == 'openai':
        #     client = openai.OpenAI(api_key=api_key)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ AI ä¾›æ‡‰å•†: {vendor}")
            
        process_history.append({'type': 'System', 'title': 'âœ… Client åˆå§‹åŒ–', 'content': f'AI Client (ä¾›æ‡‰å•†: {vendor}) æˆåŠŸåˆå§‹åŒ–ã€‚'})
            
    except Exception as e:
        error_log = [{'type': 'System', 'title': 'ğŸš¨ å®¢æˆ¶ç«¯éŒ¯èª¤', 'content': f'ç„¡æ³•åˆå§‹åŒ– AI Clientã€‚è«‹æª¢æŸ¥å¯†é‘°æˆ–ä¾›æ‡‰å•†åç¨±ã€‚éŒ¯èª¤: {str(e)}'}]
        return None, error_log

    # 2. è¦†è“‹æ¨¡å‹åç¨± (ç¢ºä¿æ‰€æœ‰ Agent ä½¿ç”¨åŒä¸€æ¨¡å‹ï¼Œå¦‚æœæä¾›äº† model_override)
    if api_config.get('model_override'):
        model_name = api_config['model_override']
        agent_initial['model'] = model_name
        for agent in AGENTS:
            agent['model'] = model_name

    # 3. åˆå§‹è‰ç¨¿ç”Ÿæˆ
    current_answer = ""
    try:
        initial_instruction = "è«‹æ ¹æ“šåŸå§‹å•é¡Œï¼Œæä¾›ä¸€å€‹çµæ§‹ç°¡å–®çš„åˆå§‹è‰ç¨¿ï¼Œä»¥ä¾¿å¾ŒçºŒ Agent é€²è¡Œç²¾ç…‰ã€‚"
        current_answer = call_ai_agent(
            agent_initial, 
            user_prompt, 
            initial_instruction, 
            client,
            vendor # å‚³éä¾›æ‡‰å•†åç¨±
        )
        process_history.append({'type': 'Agent', 'title': f'1. {agent_initial["name"]} (è‰ç¨¿ç”Ÿæˆ)', 'content': 'åˆå§‹è‰ç¨¿ç”Ÿæˆå®Œç•¢ã€‚'})
    except Exception as e:
        process_history.append({'type': 'Error', 'title': 'ğŸš¨ åˆå§‹è‰ç¨¿ç”Ÿæˆå¤±æ•—', 'content': str(e)})
        return None, process_history
    
    # 4. è¿­ä»£ç²¾ç…‰è¿´åœˆ
    for i in range(MAX_ITERATIONS):
        agent = AGENTS[i % len(AGENTS)] 
        
        try:
            refined_answer = call_ai_agent(
                agent, 
                user_prompt, 
                current_answer,
                client,
                vendor # å‚³éä¾›æ‡‰å•†åç¨±
            )
            current_answer = refined_answer 
            
            process_history.append({
                'type': 'Agent', 
                'title': f'{i+2}. {agent["name"]} (è¿­ä»£ç²¾ç…‰)', 
                'content': f'æœ¬è¼ªç²¾ç…‰å®Œæˆã€‚æ¨¡å‹: {agent["model"]}'
            })
            
        except Exception as e:
            process_history.append({'type': 'Error', 'title': f'ğŸš¨ è¿­ä»£ {i+1} å¤±æ•— ({agent["name"]})', 'content': str(e)})
            break 

    # 5. æœ€çµ‚ç­”æ¡ˆè¿”å›
    return current_answer, process_history
