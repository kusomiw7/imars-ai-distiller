# imars_core.py (æœ€çµ‚ç‰ˆ - æ”¯æ´å¤šä¾›æ‡‰å•†/å¤š Key å¾ªç’°)

import os
import itertools
from google import genai
from google.genai import types
try:
    from openai import OpenAI, APIError
except ImportError:
    OpenAI = None
    APIError = Exception
except Exception:
    OpenAI = None
    APIError = Exception


# --- 1. æµç¨‹æ§åˆ¶å¸¸æ•¸ ---
MAX_ITERATIONS = 4
TEMPERATURE_INIT = 0.8
TEMPERATURE_REFINE = 0.4


# --- 2. ä¾›æ‡‰å•†åŸºç¤é…ç½® (é—œéµ) ---
VENDOR_CONFIG = {
    "gemini": {"base_url": None, "model_prefix": "gemini"},
    "openai": {"base_url": None, "model_prefix": "gpt"},
    "deepseek": {"base_url": "https://api.deepseek.com/v1", "model_prefix": "deepseek"}
}


# --- 3. ä»£ç†æ¨¡å‹é…ç½® ---
agent_initial = {
    'name': "Drafting Agent",
    'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-3.5-turbo", "deepseek": "deepseek-coder"}, 
    'system_prompt': "ä½ æ˜¯ä¸€å€‹å¿«é€Ÿæ§‹å»ºå°ˆå®¶ã€‚è«‹æ ¹æ“šç”¨æˆ¶æç¤ºï¼Œåœ¨ä¿æŒå…§å®¹å®Œæ•´ã€çµæ§‹æ¸…æ™°çš„å‰æä¸‹ï¼Œç›´æ¥ç”Ÿæˆä¸€å€‹è©³ç›¡çš„è‰ç¨¿ç­”æ¡ˆï¼Œä¸è¼¸å‡ºä»»ä½•å‰è¨€æˆ–çµå°¾èªå¥ã€‚"
}

AGENTS = [
    {
        'name': "Logic & Factual Verifier",
        'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-4-turbo", "deepseek": "deepseek-coder"},
        'system_prompt': "ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„é‚è¼¯èˆ‡äº‹å¯¦æ ¸æŸ¥å°ˆå®¶ã€‚ä»”ç´°æª¢æŸ¥å‰ä¸€è¼ªç­”æ¡ˆçš„é‚è¼¯ä¸€è‡´æ€§å’Œäº‹å¯¦æº–ç¢ºæ€§ã€‚å¦‚æœç™¼ç¾éŒ¯èª¤æˆ–ä¸ä¸€è‡´ï¼Œè«‹åœ¨ä¿æŒåŸç­”æ¡ˆçµæ§‹çš„å‰æä¸‹é€²è¡Œæœ€å°çš„ã€ç²¾ç¢ºçš„ä¿®æ­£å’Œè£œå……ï¼Œä¸¦ä½¿ç”¨æœ€æ–°çš„ç­”æ¡ˆæ›¿æ›åŸç­”æ¡ˆã€‚"
    },
    {
        'name': "Style & Structure Polisher",
        'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-4-turbo", "deepseek": "deepseek-coder"},
        'system_prompt': "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡é¢¨å’Œçµæ§‹å„ªåŒ–å°ˆå®¶ã€‚æª¢æŸ¥å‰ä¸€è¼ªç­”æ¡ˆçš„èªæ°£ã€æµæš¢æ€§ã€å°ˆæ¥­åº¦ä»¥åŠæ ¼å¼çµæ§‹ï¼ˆä¾‹å¦‚ï¼šæ˜¯å¦ä½¿ç”¨äº†æ¸…æ™°çš„æ¨™é¡Œã€åˆ—è¡¨ã€ç²—é«”å­—ï¼‰ã€‚å¦‚æœéœ€è¦ï¼Œè«‹å„ªåŒ–æ–‡ç­†å’Œæ’ç‰ˆï¼Œä½¿ç­”æ¡ˆæ›´æ˜“æ–¼é–±è®€ï¼Œä¸¦ä½¿ç”¨æœ€æ–°çš„ç­”æ¡ˆæ›¿æ›åŸç­”æ¡ˆã€‚"
    },
    {
        'name': "Completeness Auditor",
        'model': {"gemini": "gemini-2.5-flash", "openai": "gpt-3.5-turbo", "deepseek": "deepseek-coder"},
        'system_prompt': "ä½ æ˜¯ä¸€å€‹å…§å®¹å®Œæ•´æ€§å¯©è¨ˆå“¡ã€‚æª¢æŸ¥å‰ä¸€è¼ªç­”æ¡ˆæ˜¯å¦å®Œå…¨å›ç­”äº†ç”¨æˆ¶æç¤ºä¸­çš„æ‰€æœ‰è¦æ±‚å’Œå­å•é¡Œã€‚å¦‚æœæœ‰ä»»ä½•éºæ¼æˆ–å¯ä»¥æ·±å…¥çš„ç´°ç¯€ï¼Œè«‹è£œå……ç›¸é—œå…§å®¹ï¼Œä»¥é”åˆ°æœ€å…¨é¢çš„å›ç­”ï¼Œä¸¦ä½¿ç”¨æœ€æ–°çš„ç­”æ¡ˆæ›¿æ›åŸç­”æ¡ˆã€‚"
    }
]


# --- 4. æ ¸å¿ƒ AI å‘¼å«å‡½æ•¸ ---
def call_ai_agent(agent_config, user_prompt, previous_answer, client_info):
    vendor = client_info['vendor']
    api_key = client_info['key']
    
    model_name = agent_config['model'].get(vendor)
    
    if not model_name:
        return None, f"æ¨¡å‹é…ç½®éŒ¯èª¤ï¼š{vendor} ä¾›æ‡‰å•†ç¼ºå°‘æ¨¡å‹åç¨±ã€‚"
        
    system_prompt = agent_config['system_prompt']
    
    # æ§‹å»ºæ¶ˆæ¯æ­·å²
    if previous_answer:
        prompt_with_answer = (
            f"{system_prompt}\n\n"
            f"ç”¨æˆ¶åŸå§‹æç¤º: {user_prompt}\n\n"
            f"ç•¶å‰ç­”æ¡ˆ: {previous_answer}"
        )
        messages = [{"role": "user", "content": prompt_with_answer}]
    else:
        messages = [{"role": "user", "content": f"{system_prompt}\n\nç”¨æˆ¶åŸå§‹æç¤º: {user_prompt}"}]


    try:
        if vendor == "gemini":
            client = genai.Client(api_key=api_key)
            response = client.models.generate_content(
                model=model_name,
                contents=messages,
                config=types.GenerateContentConfig(
                    system_instruction=system_prompt,
                    temperature=TEMPERATURE_INIT if not previous_answer else TEMPERATURE_REFINE,
                )
            )
            new_answer = response.text.strip()
            return new_answer, None
            
        elif vendor in ["openai", "deepseek"]:
            base_url = VENDOR_CONFIG[vendor]['base_url']
            
            client = OpenAI(
                api_key=api_key, 
                base_url=base_url if base_url else "https://api.openai.com/v1"
            )
            
            openai_messages = [{"role": "system", "content": system_prompt}] + messages
            
            response = client.chat.completions.create(
                model=model_name,
                messages=openai_messages,
                temperature=TEMPERATURE_INIT if not previous_answer else TEMPERATURE_REFINE,
            )
            new_answer = response.choices[0].message.content.strip()
            return new_answer, None
            
        else:
            return None, f"ä¸æ”¯æ´çš„ä¾›æ‡‰å•†: {vendor}"
            
    except APIError as e:
        return None, f"API å‘¼å«å¤±æ•— ({vendor}, æ¨¡å‹: {model_name}, Key Index: {client_info['index']}): {e}"
    except Exception as e:
        return None, f"API å‘¼å«å¤±æ•— ({vendor}, æ¨¡å‹: {model_name}, Key Index: {client_info['index']}): {str(e)}"

# --- 5. è’¸é¤¾å•Ÿå‹•å‡½æ•¸ ---
def start_imars_refinement(user_prompt, api_keys_pool):
    
    valid_clients = []
    process_history = []
    
    for i, client_data in enumerate(api_keys_pool):
        vendor = client_data.get('vendor', '').lower()
        key = client_data.get('key')
        
        if vendor in VENDOR_CONFIG and key and key.strip():
            valid_clients.append({
                'vendor': vendor,
                'key': key,
                'index': i + 1,
                'failed': False
            })
            process_history.append(f"Key {i+1} (ä¾›æ‡‰å•†: {vendor}) æˆåŠŸåŠ å…¥ Client Poolã€‚")
        elif key and key.strip():
            process_history.append(f"Key {i+1} (ä¾›æ‡‰å•†: {vendor}) å¤±æ•—ï¼šä¸æ”¯æ´çš„ä¾›æ‡‰å•†æˆ– Key ç„¡æ•ˆã€‚")

    
    if not valid_clients:
        return None, ["ğŸš¨ åš´é‡éŒ¯èª¤: æ‰€æœ‰æä¾›çš„å¯†é‘°éƒ½ç„¡æ•ˆæˆ–ä¾›æ‡‰å•†ä¸è¢«æ”¯æ´ã€‚"]
        
    
    key_iterator = itertools.cycle(range(len(valid_clients)))
    process_history.insert(0, "âœ… Client åˆå§‹åŒ–")
    
    final_answer = None
    
    # 1. åˆå§‹è‰ç¨¿
    current_key_index = next(key_iterator)
    client_info = valid_clients[current_key_index]
    
    process_history.append(f"1. Drafting Agent (Key {client_info['index']} ä¾›æ‡‰å•†: {client_info['vendor']} è‰ç¨¿ç”Ÿæˆ)")
    
    draft, error = call_ai_agent(agent_initial, user_prompt, None, client_info)
    
    if error:
        process_history.append(f"ğŸš¨ åˆå§‹è‰ç¨¿ç”Ÿæˆå¤±æ•—: {error}")
        return None, process_history
        
    final_answer = draft
    
    # 2. è¿­ä»£ç²¾ç…‰
    for i in range(MAX_ITERATIONS):
        agent_config = AGENTS[i % len(AGENTS)] 
        
        current_key_index = next(key_iterator)
        client_info = valid_clients[current_key_index]
        
        step_name = f"{i + 2}. {agent_config['name']} (Key {client_info['index']} ä¾›æ‡‰å•†: {client_info['vendor']} è¿­ä»£ç²¾ç…‰)"
        process_history.append(step_name)
        
        refined_answer, error = call_ai_agent(agent_config, user_prompt, final_answer, client_info)
        
        if error:
            process_history.append(f"ğŸš¨ ç¬¬ {i + 2} æ­¥ç²¾ç…‰å¤±æ•—: {error}")
            if i > 0 and 'å¤±æ•—' in process_history[-2]:
                process_history.append("ğŸš¨ é€£çºŒå…©æ¬¡ç²¾ç…‰å¤±æ•—ï¼Œæµç¨‹çµ‚æ­¢ã€‚")
                break
            continue
            
        final_answer = refined_answer
        
    return final_answer, process_history
